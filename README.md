# SearchEngine
This is a simple search engine built on an inverted index using MapReduce (mrjob)

This toy search engine is built on a corpus consisting of 10k Wikipedia pages. Each document passes through `nltk.tokenize.word_tokenize` and then `nltk.stem.SnowballStemmer` to reduce the size of vocabulary. Note that one could opt to filter out non-English words using `nltk.corpus.words`, but this results in a significant loss of content because, for example, plural nouns and conjugated verbs will be removed. Instead, we chose to adopt the regex expression `^[a-z][a-z\-]*$` so that we include all words starting with an English character which possibly contains hyphens.

After each document is tokenized and stemmed, it goes through two MapReduce phases (`inverted_index.py`). The first mapper yields key-value pairs in which a key consist of a word stem and the document id from which the word is extracted, and the values are 1. The first reducer aggregates the mapper's output by summing across, returning the `count`s of (`document_id`, `word_stem`) pairs. The second mapper reshuffles the key and value into `word_stem`:(`document_id`,`count`) and the second reducer collects for each `word_stem` a dictionary of `document_id`:`count` pairs by summation. The output is then an inverted index which allows us to efficiently retrieve all the documents where a word (stem) appears, along with their frequencies. 

The inverted index is naturally loaded as a dictionary in `search_engine.py` in which a command lint interface is implemented. When the user inputs a search query, it is first tokenized and stemmed as described above. For each word stem, its `doucment_id`:`count` dictionary is retrieved, and we take the intersection of the `document_id`s where all stems are found. If the result is empty we return the seach with no matches. Else, for each word stem we filter its associated dictionary by keeping only those documents that contain all query word stems and calculate the td-tdf score. The score for each matched document is given by the sum of its td-tdf score across all query word stems. The matched documents are then ranked by its score in a descending order. The top 10 matches are displayed in their `document_id`, title, and a snippet around the first occurrence of the first search keyword.
